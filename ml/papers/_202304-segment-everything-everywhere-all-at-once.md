# Segment Everything Everywhere All at Once

- https://arxiv.org/abs/2304.06718
- Xueyan Zou at al.
- authors are from
  - University of Wisconsin-Madison
  - Microsoft Research at Redmond
  - HKUST
  - Microsoft Cloud and AI
- SEEM
- https://github.com/UX-Decoder/Segment-Everything-Everywhere-All-At-Once
- TODO
  - what does interpolation mean here in this paper?
  - what is the `Match` function, and what does it do actually.
  - what are generalist and composition type in the table 1
  - what does cIoU mean?
  - How is SAM helpful for future improvement of SEEM.




## 1 Introduction

## 2 Related work

##### Close-set segmentation

##### Open-set segmentation

##### Interactive segmentation

## 3 Method

**TODO**

- Add Figure 3 and 4
- Add formulas somehow...

##### Versatile

##### Compositional

##### Interactive

##### Semantic-aware

## 4 Experiments

##### Dataset and settings

##### Implementation detail and evaluation metrics

### 4.1 Interactive segmentation

### 4.2 Generic segmentation

### 4.3 Referring segmentation

### 4.4 Ablation study

### 4.5 Qualitative results

##### Visual prompt interactive segmentation

##### Text referring segmentation

##### Visual referring segmentation



## 5 Conclusion

##### Limitations and future works

- trained on a relatively small dataset - COCO
  - compared to SAM

## References

- [8] Mask2Former
- [65] X-Decoder



## Notes

### Summary of related papers

#### Per-Pixel Classification is Not All You Need for Semantic Segmentation

- https://arxiv.org/abs/2107.06278
- Facebook
- Bowen Cheng at al.
- MaskFormer
- **TODO**

#### Masked-attention Mask Transformer for Universal Image Segmentation

- https://arxiv.org/abs/2112.01527
- Facebook
- Bowen Cheng at al.
- Mask2Former
- **TODO**

#### Generalized Decoding for Pixel, Image, and Language

- https://arxiv.org/abs/2212.11270
- Microsoft
- Xueyan Zou at al.
- X-Decoder
- **TODO**
